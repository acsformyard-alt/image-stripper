<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Upper-Right Text Remover — LaMa (Local model, Cloudflare Pages)</title>
  <link rel="stylesheet" href="/styles.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.22.0/ort.webgpu.min.js"></script>

</head>
<body>
  <header>
    <h1>Upper-Right Text Remover (Local LaMa model)</h1>
    <p class="muted">
      Deployed on Cloudflare Pages. Select a <code>.onnx</code> model from your computer (not uploaded), then pick images.
      WebGPU runs because the site is HTTPS; nothing leaves your device.
    </p>
  </header>

  <main>
    <section class="controls">
      <label class="btn">
        <input id="modelInput" type="file" accept=".onnx" />
        Choose LaMa model (.onnx)
      </label>

      <label class="btn">
        <input id="fileInput" type="file" accept="image/*" multiple />
        Choose images
      </label>

      <button id="processBtn" class="primary" disabled>Process</button>
      <span id="status" class="status">Pick model, then images.</span>

      <span class="pill" id="modelName">No model selected</span>
      <span class="pill" id="imagesInfo">No images</span>
    </section>

    <section>
      <div id="gallery" class="gallery"></div>
    </section>
  </main>

  <div id="globalSpinner" class="spinner" aria-hidden="true"></div>

  <pre id="log" class="log"></pre>

  <script type="module">
    import { initLamaFromBuffer, inpaintUpperRightBatch, setExecutionProviders } from '/js/lama.js';
    import { uiInit, setModelLabel, setBusy, wireImagePicker } from '/js/app.js';

    const statusEl   = document.getElementById('status');
    const modelInput = document.getElementById('modelInput');
    const modelName  = document.getElementById('modelName');
    const processBtn = document.getElementById('processBtn');
    const logEl      = document.getElementById('log');

    const log = (m) => { logEl.textContent += m + "\n"; };

    // Prefer WebGPU; ORT will fall back to WASM automatically if needed
    setExecutionProviders(['webgpu','wasm']);

    // Basic UX init
    uiInit({ inpaintBatch: inpaintUpperRightBatch, statusEl });
    wireImagePicker();

    // Safety: enable Process only when both model + at least one image are selected
    const filesInput = document.getElementById('fileInput');
    const syncProcessEnabled = () => {
      const hasModel  = modelName.textContent !== 'No model selected';
      const hasImages = filesInput.files && filesInput.files.length > 0;
      processBtn.disabled = !(hasModel && hasImages);
    };
    filesInput.addEventListener('change', syncProcessEnabled);

    // Manual model loading from local disk (no fetch, no 25MB limit)
    modelInput.addEventListener('change', async () => {
      const f = modelInput.files?.[0];
      if (!f) return;
      setModelLabel(f.name);
      syncProcessEnabled();
      try {
        setBusy(true, 'Reading model…');
        const buf = await f.arrayBuffer();
        setBusy(true, 'Initializing LaMa…');
        await initLamaFromBuffer(new Uint8Array(buf));
        statusEl.textContent = 'Model ready. Choose images.';
        log('Model initialized: ' + f.name);
      } catch (e) {
        console.error(e);
        log('Model init error: ' + (e.message || e));
        statusEl.textContent = 'Failed to initialize model.';
      } finally {
        setBusy(false);
        syncProcessEnabled();
      }
    });

    // Quick environment diagnostics
    if (typeof ort === 'undefined') {
      statusEl.textContent = 'onnxruntime-web not loaded. (Check CDN or /lib/ path.)';
      log('ERROR: ort is undefined (script failed to load).');
    } else {
      log('onnxruntime-web loaded. WebGPU available: ' + ('gpu' in navigator));
    }
  </script>
</body>
</html>
